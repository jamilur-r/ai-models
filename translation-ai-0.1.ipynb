{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8432f536-7082-44d3-89c5-4501ff465d2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.23.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\jamilur\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d63ad5f7-2eba-4ca1-b2b5-b558957f4c0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sklearn) (1.1.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.23.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (58.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.47.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.9.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (1.8.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\jamilur\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "898ec549-7e35-418a-a1fa-530da476e841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.23.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\jamilur\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb6efc9-ffaf-4d25-9308-0d69b949dd84",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "13f40438-cc4b-45b9-9caa-cd65a12c8dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_text</th>\n",
       "      <th>th_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Doesn't snap together well.</td>\n",
       "      <td>เข้ากันไม่ค่อยดี</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charged it after every use as directed for abo...</td>\n",
       "      <td>เรียกเก็บเงินหลังจากใช้งานทุกครั้งตามที่กำกับไ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My son wanted this movie so badly, that he sai...</td>\n",
       "      <td>ลูกชายของฉันต้องการภาพยนตร์เรื่องนี้เพื่อไม่ดี...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>But his writing has degenerated in later books.</td>\n",
       "      <td>แต่หนังสือเล่มที่ผ่านมาของเขามันดูด้อยคุณภาพลง</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was supposed to be a good bag, well you get...</td>\n",
       "      <td>มันควรที่จะเป็นกระเป๋าที่ดี เอ้อ เธอได้ในสิ่งท...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             en_text  \\\n",
       "0                        Doesn't snap together well.   \n",
       "1  Charged it after every use as directed for abo...   \n",
       "2  My son wanted this movie so badly, that he sai...   \n",
       "3    But his writing has degenerated in later books.   \n",
       "4  It was supposed to be a good bag, well you get...   \n",
       "\n",
       "                                             th_text  \n",
       "0                                   เข้ากันไม่ค่อยดี  \n",
       "1  เรียกเก็บเงินหลังจากใช้งานทุกครั้งตามที่กำกับไ...  \n",
       "2  ลูกชายของฉันต้องการภาพยนตร์เรื่องนี้เพื่อไม่ดี...  \n",
       "3     แต่หนังสือเล่มที่ผ่านมาของเขามันดูด้อยคุณภาพลง  \n",
       "4  มันควรที่จะเป็นกระเป๋าที่ดี เอ้อ เธอได้ในสิ่งท...  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('translation-dataset/generated_reviews_crowd.csv')\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bc5c7982-3488-4ccd-b72e-684f82071a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24587, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_text</th>\n",
       "      <th>th_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Doesn't snap together well.</td>\n",
       "      <td>เข้ากันไม่ค่อยดี</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charged it after every use as directed for abo...</td>\n",
       "      <td>เรียกเก็บเงินหลังจากใช้งานทุกครั้งตามที่กำกับไ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My son wanted this movie so badly, that he sai...</td>\n",
       "      <td>ลูกชายของฉันต้องการภาพยนตร์เรื่องนี้เพื่อไม่ดี...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             en_text  \\\n",
       "0                        Doesn't snap together well.   \n",
       "1  Charged it after every use as directed for abo...   \n",
       "2  My son wanted this movie so badly, that he sai...   \n",
       "\n",
       "                                             th_text  \n",
       "0                                   เข้ากันไม่ค่อยดี  \n",
       "1  เรียกเก็บเงินหลังจากใช้งานทุกครั้งตามที่กำกับไ...  \n",
       "2  ลูกชายของฉันต้องการภาพยนตร์เรื่องนี้เพื่อไม่ดี...  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e6b77187-f36d-43b5-9b64-93c190bafa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning\n",
    "from string import punctuation\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "def clean_string(string):\n",
    "    # Replace no-break space with space\n",
    "    string = string.replace(\"\\u202f\",\" \")\n",
    "    # Converts all uppercase characters into lowercase characters\n",
    "    string = string.lower()\n",
    "\n",
    "    # Delete the punctuation and the numbers\n",
    "    for p in punctuation + \"«»\" + \"0123456789\":\n",
    "        string = string.replace(p,\" \")\n",
    "\n",
    "    # Eliminate duplicate whitespaces using wildcards   \n",
    "    string = re.sub(\"\\s+\",\" \", string)\n",
    "    # Remove spaces at the beginning and at the end of the string\n",
    "    string = string.strip()\n",
    "           \n",
    "    return string\n",
    "dataset[\"en_text\"] = dataset[\"en_text\"].astype(str)\n",
    "dataset[\"th_text\"]  = dataset[\"th_text\"].astype(str)\n",
    "\n",
    "dataset[\"en_text\"] = dataset[\"en_text\"].apply(lambda x: clean_string(x))\n",
    "dataset[\"th_text\"]  = dataset[\"th_text\"].apply(lambda x: clean_string(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b905a97a-d704-425f-91d6-e1659bf4ab1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[start] will stop using since can t afford doing every time its full [end]\n",
      "[start] i have found that this book is rather weak when it comes to explaining why the authors recommend certain tips [end]\n",
      "[start] the product they sent me didn t even look like what you see here and certainly wasn t the item pictured on amazon [end]\n",
      "[start] most obvious was that you need an awful lot of knowledge or understanding about how people think on a daily basis at least if you re going for plausible fiction [end]\n",
      "[start] have had these now about months [end]\n",
      "\n",
      "---------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('เข้ากันไม่ค่อยดี', '[start] doesn t snap together well [end]'),\n",
       " ('เรียกเก็บเงินหลังจากใช้งานทุกครั้งตามที่กำกับไว้เป็นเวลาประมาณ เดือนเริ่มมีปัญหาในการเก็บประจุ',\n",
       "  '[start] charged it after every use as directed for about months started having difficulty holding a charge on it [end]'),\n",
       " ('ลูกชายของฉันต้องการภาพยนตร์เรื่องนี้เพื่อไม่ดี ที่เขากล่าวว่ามันอย่างน้อย ครั้ง',\n",
       "  '[start] my son wanted this movie so badly that he said it at least times [end]'),\n",
       " ('แต่หนังสือเล่มที่ผ่านมาของเขามันดูด้อยคุณภาพลง',\n",
       "  '[start] but his writing has degenerated in later books [end]'),\n",
       " ('มันควรที่จะเป็นกระเป๋าที่ดี เอ้อ เธอได้ในสิ่งที่เธอจ่ายไป',\n",
       "  '[start] it was supposed to be a good bag well you get what you pay for [end]')]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_en = dataset[\"en_text\"].values\n",
    "raw_data_th = dataset[\"th_text\"].values\n",
    "\n",
    "# Add start and end\n",
    "raw_data_en_in_out = [\"[start] \" + st + \" [end]\" for st in raw_data_en]\n",
    "\n",
    "for _ in range(5):\n",
    "    print(random.choice(raw_data_en_in_out))\n",
    "\n",
    "print(\"\\n---------------------------------------------------------------------\")\n",
    "# Each line contains an English sentence and its corresponding French sentence. \n",
    "# The English sentence is the source sequence and the French one is the target sequence.\n",
    "my_data = []\n",
    "for i in range(len(raw_data_th)):\n",
    "    th = raw_data_th[i]\n",
    "    en = raw_data_en_in_out[i]\n",
    "    my_data.append((th, en))\n",
    "    \n",
    "my_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4f3e97a6-f6c1-4419-b756-e4bc1d31cfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs in my dtat :  24587\n",
      "Training pairs         :  19671\n",
      "Validation pairs       :  2458\n",
      "Test pairs             :  2458\n"
     ]
    }
   ],
   "source": [
    "# Shuffle dataset\n",
    "\n",
    "random.shuffle(my_data)\n",
    "\n",
    "# Train_set = 80%, Test_set = 10%, Val_set = 10%\n",
    "num_val_samples = int(0.1 * len(my_data))\n",
    "num_train_samples = len(my_data) - 2 * num_val_samples\n",
    "\n",
    "train_pairs = my_data[:num_train_samples]\n",
    "val_pairs   = my_data[num_train_samples : num_train_samples + num_val_samples]\n",
    "test_pairs  = my_data[num_train_samples + num_val_samples :]\n",
    "\n",
    "print(\"Total pairs in my dtat : \",len(my_data))\n",
    "print(\"Training pairs         : \",len(train_pairs))\n",
    "print(\"Validation pairs       : \",len(val_pairs))\n",
    "print(\"Test pairs             : \",len(test_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2c26f4ab-8ef2-4951-bba3-69eb6adf7c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6bf29bd8-45dc-42d9-a168-97cd0ee4b97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Vectorizing the text data\n",
    "vocab_size      = 15000\n",
    "sequence_length = 25\n",
    "batch_size      = 64\n",
    "\n",
    "en_vectorization = TextVectorization(\n",
    "    max_tokens = vocab_size, output_mode = \"int\", \n",
    "    output_sequence_length = sequence_length + 1,)\n",
    "\n",
    "th_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,)\n",
    "\n",
    "train_th_texts = [pair[0] for pair in train_pairs]\n",
    "train_en_texts = [pair[1] for pair in train_pairs]\n",
    "\n",
    "en_vectorization.adapt(train_en_texts)\n",
    "th_vectorization.adapt(train_th_texts)\n",
    " \n",
    "print(\"Done ...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "63ac4b87-0aa4-4552-9570-cb096e3f4e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs[\"encoder_inputs\"].shape: (64, 25)\n",
      "inputs[\"decoder_inputs\"].shape: (64, 25)\n",
      "targets.shape: (64, 25)\n"
     ]
    }
   ],
   "source": [
    "def format_dataset(en, th):\n",
    "    th = th_vectorization(th)\n",
    "    en = en_vectorization(en)\n",
    "    return ({\"encoder_inputs\": th, \"decoder_inputs\": en[:, :-1],}, en[:, 1:])\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    th_texts, en_texts = zip(*pairs)\n",
    "\n",
    "    th_texts = list(th_texts)\n",
    "    en_texts = list(en_texts)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((en_texts, th_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.shuffle(1024).prefetch(32).cache()\n",
    "\n",
    "\n",
    "train_dataset = make_dataset(train_pairs)\n",
    "val_dataset   = make_dataset(val_pairs)\n",
    "\n",
    "for inputs, targets in train_dataset.take(1):\n",
    "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
    "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a7af35b1-5275-4913-af75-090c7d14dc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ...\n"
     ]
    }
   ],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
    "         #-----------------------------------------------------------------------\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size      = vocab_size\n",
    "        self.embed_dim       = embed_dim\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "        # L3\n",
    "        self.input_embeddings = layers.Embedding(\n",
    "                                     input_dim=vocab_size, output_dim=embed_dim)\n",
    "        \n",
    "        #-----------------------------------------------------------------------\n",
    "        # L4\n",
    "        self.positional_encoding = layers.Embedding(\n",
    "                                input_dim=sequence_length, output_dim=embed_dim)\n",
    "       \n",
    "    #---------------------------------------------------------------------------\n",
    "    def call(self, inputs):\n",
    "        length    = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "\n",
    "        # L3\n",
    "        embedded_inputs    = self.input_embeddings(inputs)\n",
    "        # L4\n",
    "        embedded_positions = self.positional_encoding(positions)\n",
    "        # L5\n",
    "        return embedded_inputs + embedded_positions\n",
    "\n",
    "    #---------------------------------------------------------------------------\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "        \n",
    "#*******************************************************************************\n",
    "print(\"Done ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b64eb429-692b-47dc-b914-68733b821141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ...\n"
     ]
    }
   ],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        #-----------------------------------------------------------------------\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        # L6\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "                                         num_heads=num_heads, key_dim=embed_dim)\n",
    "        # L8\n",
    "        self.feed_forward = keras.Sequential([\n",
    "                                  layers.Dense(dense_dim, activation=\"relu\"), \n",
    "                                   layers.Dense(embed_dim),])\n",
    "        \n",
    "        # L7\n",
    "        self.normalization_1  = layers.LayerNormalization()\n",
    "        # L9\n",
    "        self.normalization_2  = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    #---------------------------------------------------------------------------\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "        # L6\n",
    "        attention_output = self.attention(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask)\n",
    "        \n",
    "        #-----------------------------------------------------------------------\n",
    "        # L7\n",
    "        addnorm_output_1 = self.normalization_1(inputs + attention_output)\n",
    "        # L8\n",
    "        feedforward_output = self.feed_forward(addnorm_output_1)\n",
    "        # L9\n",
    "        addnorm_output_2 = self.normalization_2(addnorm_output_1 + feedforward_output)\n",
    "        # L10\n",
    "        return addnorm_output_2\n",
    "\n",
    "#*******************************************************************************\n",
    "print(\"Done ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e04d44c6-b800-4696-b001-325a31d4fa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        #-----------------------------------------------------------------------\n",
    "        self.embed_dim  = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads  = num_heads\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "        # L11\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "                                         num_heads=num_heads, key_dim=embed_dim)\n",
    "        # L13\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "                                         num_heads=num_heads, key_dim=embed_dim)\n",
    "        #-----------------------------------------------------------------------\n",
    "        # L15\n",
    "        self.feed_forward = keras.Sequential([\n",
    "          layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),])\n",
    "        \n",
    "        # L12\n",
    "        self.normalization_1  = layers.LayerNormalization()\n",
    "        # L14\n",
    "        self.normalization_2  = layers.LayerNormalization()\n",
    "        # L16\n",
    "        self.normalization_3  = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    #---------------------------------------------------------------------------\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "        # L11\n",
    "        attention_output_1 = self.attention_1(\n",
    "             query=inputs, value=inputs, key=inputs, attention_mask=causal_mask)\n",
    "        # L12\n",
    "        addnorm_output_1 = self.normalization_1(inputs + attention_output_1)\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "        # L13\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=addnorm_output_1, value=encoder_outputs, key=encoder_outputs,\n",
    "            attention_mask=padding_mask,)\n",
    "        # L14\n",
    "        addnorm_output_2 = self.normalization_2(addnorm_output_1 + attention_output_2)\n",
    "\n",
    "        #-----------------------------------------------------------------------\n",
    "        # L15\n",
    "        feedforward_output = self.feed_forward(addnorm_output_2)\n",
    "        # L16\n",
    "        addnorm_output_3 = self.normalization_3(addnorm_output_2 + feedforward_output)\n",
    "\n",
    "        return addnorm_output_3\n",
    "\n",
    "    #---------------------------------------------------------------------------\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "            axis=0,\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n",
    "        \n",
    "#*******************************************************************************\n",
    "print(\"Done ...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7a387a64-8677-4b51-849e-8343823844b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: graphviz in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.20)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydot) (3.0.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\jamilur\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3df30cbe-6174-45c2-9372-fe6704640f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " positional_embedding_12 (Posit  (None, None, 128)   1923200     ['encoder_inputs[0][0]']         \n",
      " ionalEmbedding)                                                                                  \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " transformer_encoder_6 (Transfo  (None, None, 128)   923136      ['positional_embedding_12[0][0]']\n",
      " rmerEncoder)                                                                                     \n",
      "                                                                                                  \n",
      " model_13 (Functional)          (None, None, 15000)  5440920     ['decoder_inputs[0][0]',         \n",
      "                                                                  'transformer_encoder_6[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,287,256\n",
      "Trainable params: 8,287,256\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "embed_dim  = 128\n",
    "latent_dim = 1024\n",
    "num_heads  = 10\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# L1\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "# L3, L4, L5\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# From L6 to L10\n",
    "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
    "# Encoder\n",
    "encoder         = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# L2\n",
    "decoder_inputs     = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
    "# L10\n",
    "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
    "# L3, L4, L5\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "# From L11 to L16\n",
    "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# Output Probabilities\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# Decoder\n",
    "decoder         = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# My Transformer\n",
    "my_transformer = keras.Model(\n",
    "                          [encoder_inputs, decoder_inputs], \n",
    "                          decoder_outputs, name=\"my_transformer\")\n",
    "\n",
    "# The model’s summary() method displays all the model’s layers\n",
    "print(my_transformer.summary())\n",
    "\n",
    "# Plot the model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(my_transformer, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8f1c0aec-cbed-4c00-8983-5b49a7d989a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-addons in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-addons) (21.3)\n",
      "Requirement already satisfied: typeguard>=2.7 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->tensorflow-addons) (3.0.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\jamilur\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dc75cac5-6943-42dd-95f5-f54a5a47c644",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "308/308 [==============================] - 228s 732ms/step - loss: 3.6995 - accuracy: 0.1497 - val_loss: 3.2109 - val_accuracy: 0.1941\n",
      "Epoch 2/20\n",
      "308/308 [==============================] - 222s 720ms/step - loss: 3.1532 - accuracy: 0.2013 - val_loss: 3.0709 - val_accuracy: 0.2074\n",
      "Epoch 3/20\n",
      "308/308 [==============================] - 224s 729ms/step - loss: 2.9937 - accuracy: 0.2171 - val_loss: 3.0117 - val_accuracy: 0.2128\n",
      "Epoch 4/20\n",
      "308/308 [==============================] - 222s 722ms/step - loss: 2.8742 - accuracy: 0.2309 - val_loss: 2.9798 - val_accuracy: 0.2136\n",
      "Epoch 5/20\n",
      "308/308 [==============================] - 222s 720ms/step - loss: 2.7741 - accuracy: 0.2435 - val_loss: 2.9597 - val_accuracy: 0.2203\n",
      "Epoch 6/20\n",
      "308/308 [==============================] - 223s 724ms/step - loss: 2.6857 - accuracy: 0.2554 - val_loss: 2.9750 - val_accuracy: 0.2218\n",
      "Epoch 7/20\n",
      "308/308 [==============================] - 255s 829ms/step - loss: 2.6067 - accuracy: 0.2672 - val_loss: 2.9649 - val_accuracy: 0.2183\n",
      "Epoch 8/20\n",
      "308/308 [==============================] - 255s 827ms/step - loss: 2.5354 - accuracy: 0.2773 - val_loss: 3.0026 - val_accuracy: 0.2195\n",
      "Epoch 9/20\n",
      "308/308 [==============================] - 255s 828ms/step - loss: 2.4655 - accuracy: 0.2885 - val_loss: 3.0310 - val_accuracy: 0.2214\n",
      "Epoch 10/20\n",
      "308/308 [==============================] - 248s 805ms/step - loss: 2.4003 - accuracy: 0.2987 - val_loss: 3.0133 - val_accuracy: 0.2234\n",
      "Epoch 11/20\n",
      "308/308 [==============================] - 238s 772ms/step - loss: 2.3398 - accuracy: 0.3104 - val_loss: 3.0034 - val_accuracy: 0.2248\n",
      "Epoch 12/20\n",
      "308/308 [==============================] - 252s 819ms/step - loss: 2.2855 - accuracy: 0.3201 - val_loss: 3.0353 - val_accuracy: 0.2196\n",
      "Epoch 13/20\n",
      "308/308 [==============================] - 243s 790ms/step - loss: 2.2293 - accuracy: 0.3314 - val_loss: 3.0705 - val_accuracy: 0.2158\n",
      "Epoch 14/20\n",
      "308/308 [==============================] - 241s 783ms/step - loss: 2.1783 - accuracy: 0.3413 - val_loss: 3.0980 - val_accuracy: 0.2170\n",
      "Epoch 15/20\n",
      "308/308 [==============================] - 222s 719ms/step - loss: 2.1247 - accuracy: 0.3527 - val_loss: 3.1154 - val_accuracy: 0.2164\n",
      "Epoch 16/20\n",
      "308/308 [==============================] - 254s 824ms/step - loss: 2.0755 - accuracy: 0.3637 - val_loss: 3.1406 - val_accuracy: 0.2155\n",
      "Epoch 17/20\n",
      "308/308 [==============================] - 256s 831ms/step - loss: 2.0262 - accuracy: 0.3745 - val_loss: 3.1831 - val_accuracy: 0.2187\n",
      "Epoch 18/20\n",
      "308/308 [==============================] - 255s 829ms/step - loss: 1.9809 - accuracy: 0.3840 - val_loss: 3.1829 - val_accuracy: 0.2199\n",
      "Epoch 19/20\n",
      "308/308 [==============================] - 256s 832ms/step - loss: 1.9406 - accuracy: 0.3922 - val_loss: 3.1886 - val_accuracy: 0.2159\n",
      "Epoch 20/20\n",
      "308/308 [==============================] - 256s 830ms/step - loss: 1.9026 - accuracy: 0.4006 - val_loss: 3.2263 - val_accuracy: 0.2179\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate = 0.001, weight_decay=0.0001)\n",
    "\n",
    "# Compiling the model\n",
    "my_transformer.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                       optimizer = optimizer, metrics = [\"accuracy\"])\n",
    "\n",
    "# Training the model \n",
    "epochs = 20 # You have to train it longer to converge\n",
    "history = my_transformer.fit(train_dataset, epochs=epochs, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "87c08239-a938-47ad-975a-2041982c5d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\jamilur\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading matplotlib-3.5.2-cp310-cp310-win_amd64.whl (7.2 MB)\n",
      "     ---------------------------------------- 7.2/7.2 MB 472.3 kB/s eta 0:00:00\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.34.4-py3-none-any.whl (944 kB)\n",
      "     ------------------------------------ 944.1/944.1 KB 686.7 kB/s eta 0:00:00\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.23.1)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp310-cp310-win_amd64.whl (55 kB)\n",
      "     -------------------------------------- 55.3/55.3 KB 726.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.2.0-cp310-cp310-win_amd64.whl (3.3 MB)\n",
      "     ---------------------------------------- 3.3/3.3 MB 337.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jamilur\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pillow, kiwisolver, fonttools, cycler, matplotlib\n",
      "Successfully installed cycler-0.11.0 fonttools-4.34.4 kiwisolver-1.4.4 matplotlib-3.5.2 pillow-9.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "462ef744-0665-4628-a1d0-a6ba696bb156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 13s 339ms/step - loss: 3.2377 - accuracy: 0.2183\n",
      "Loss     :  3.2377452850341797\n",
      "accuracy :  0.21825067698955536\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history.history).plot(figsize=(12, 8))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model\n",
    "test_dataset   = make_dataset(test_pairs)\n",
    "model_evaluate = my_transformer.evaluate(test_dataset)\n",
    "print(\"Loss     : \",model_evaluate[0])\n",
    "print(\"accuracy : \",model_evaluate[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f1d6b79a-deeb-488e-8782-2fbe9a877933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example :  0\n",
      "TH:  นี่เป็นกล้องดิจิตอลตัวแรกของฉันที่ไม่ได้มาพร้อมกับคู่มือการใช้งาน\n",
      "EN:   i m not sure if it s worth buying   buying  this  my  up with led\n",
      "-------------------------------------------------------------------\n",
      "Example :  1\n",
      "TH:  รูปภาพก็สวยซะด้วย\n",
      "EN:   i m not sure if it s worth buying it    for buying  and it fixed more\n",
      "-------------------------------------------------------------------\n",
      "Example :  2\n",
      "TH:  ฉันตื่นเต้นมากๆ เมื่อหนังสือมาอยู่ในกล่องจดหมายของฉัน เพราะได้ยินมาว่ามันน่าสนใจ แต่พออ่านแล้วกลับน่าเบื่อ\n",
      "EN:   i m not sure if it s worth buying    buying  buying another   from amazon\n",
      "-------------------------------------------------------------------\n",
      "Example :  3\n",
      "TH:  ผมผิดหวังเล็กน้อยกับหนังสือเล่มนี้เป็นหลักฐานที่น่าสนใจและเธอสร้างตัวละครที่น่าสนใจมากบาง\n",
      "EN:   i m not sure if it s worth buying      buying the    \n",
      "-------------------------------------------------------------------\n",
      "Example :  4\n",
      "TH:  เกมนี้สนุกดี กราฟฟิคสวยและก็มีเนื้อหาใหม่ๆอยู่เสมอ\n",
      "EN:   i m not sure if it s worth buying      buying the    \n",
      "-------------------------------------------------------------------\n",
      "Example :  5\n",
      "TH:  นอกจากนี้มุมมองของเขาในอิรักอาจมีขึ้นอยู่กับแหล่งเดียวเพียงอย่างเดียวคืออดีตเจ้านายอดีตประธานาธิบดีบุช\n",
      "EN:   i m not sure if it s worth buying      buying the  up with it\n",
      "-------------------------------------------------------------------\n",
      "Example :  6\n",
      "TH:  แม้ว่าราคานั้นจะถูกมากและเธอได้สองขวด พวกเขาก็ค่อนข้างไร้ประโยชน์สำหรับการลิ้มรสจริงๆสินค้าจะดีแค่ไหนกัน\n",
      "EN:   i m not sure if it s worth buying      buying the  up with it\n",
      "-------------------------------------------------------------------\n",
      "Example :  7\n",
      "TH:  สำหรับ ใหม่ล่าสุด ช่างน่าผิดหวังมาก\n",
      "EN:   i m not sure if it s worth buying      buying the  up with it\n",
      "-------------------------------------------------------------------\n",
      "Example :  8\n",
      "TH:  นี่คือหนังสือที่มีประโยชน์และเหมาะกับฉันมาก\n",
      "EN:   i m not sure if it s worth buying      buying the    \n",
      "-------------------------------------------------------------------\n",
      "Example :  9\n",
      "TH:  หวังว่าเราจะได้พบกับบางสิ่งบางอย่างอย่างน้อยเป็นอย่างดีในเร็ว ๆ นี้\n",
      "EN:   however there are some good pictures and most of the pieces come off   attached  with power \n",
      "-------------------------------------------------------------------\n",
      "Example :  10\n",
      "TH:  อย่างไรก็ตามมันใช้ได้กับคอมพิวเตอร์เครื่องอื่นที่ใช้แบตเตอรี่แบบเดียวกันนี้\n",
      "EN:   i m not sure if it s worth buying      buying the    \n",
      "-------------------------------------------------------------------\n",
      "Example :  11\n",
      "TH:  ไฟสีแดงสว่างขึ้น แต่ตอนนี้ไม่มีอะไรใช้งานได้เลยอ่ะ\n",
      "EN:   i m not sure if it s worth buying      buying the    \n",
      "-------------------------------------------------------------------\n",
      "Example :  12\n",
      "TH:  นักเขียนตั้งใจแสดงทักษะการเขียนของเขา แต่ไม่สามารถดึงดูดผู้อ่านให้มีความสนใจอย่างแท้จริงได้\n",
      "EN:   i m not sure if it s worth buying      buying the    \n",
      "-------------------------------------------------------------------\n",
      "Example :  13\n",
      "TH:  และเสียง ฉันหมายถึงดังจนทนไม่ไหวเทียบกับเครื่องเล่นดีวีดีอื่นที่เธอมี ไม่สำคัญว่าราคาเท่าไรห่\n",
      "EN:   i m not sure if it s worth buying      buying the    \n",
      "-------------------------------------------------------------------\n",
      "Example :  14\n",
      "TH:  ข้อความในรูปแบบนี้ดูเหมือนจะถูกคัดลอกจากสำเนาเก่าของ\n",
      "EN:   it was a bit too long as i ve had been using it for years     \n",
      "-------------------------------------------------------------------\n",
      "Example :  15\n",
      "TH:  น่าเสียดายที่ฉันพบว่ามันไม่เพียงแต่ยากและมีราคาแพง แต่มีข้อบกพร่องเช่นกัน\n",
      "EN:   it is a good idea as well as i m not sure if you are looking for something  \n",
      "-------------------------------------------------------------------\n",
      "Example :  16\n",
      "TH:  ผู้เขียนไม่ได้จริงๆรู้วิธีการแสดงวัสดุของเขาเพราะเขาดูเหมือนจะสับสนเกี่ยวกับสิ่งที่โปรแกรมคอมพิวเตอร์เป็น\n",
      "EN:   i m not sure if it s worth buying      buying the    \n",
      "-------------------------------------------------------------------\n",
      "Example :  17\n",
      "TH:  มันคือเวลาที่จะลองบางอย่างที่แพงกว่านี้ ทำโดยใครบางคนที่มีการประสบความสำเร็จในการทำให้ลูกค้าของพวกเขามีความสุข และแน่นอนว่าไม่ใช่ผ่านทางอะเมซอน\n",
      "EN:   i m not sure if it s worth buying      buying the  up with it\n",
      "-------------------------------------------------------------------\n",
      "Example :  18\n",
      "TH:  หนังสือเล่มนี้ดูเยี่ยมไปเลย ฉันรอที่จะสั่งซื้อมันสำหรับเป็นของขวัญก่อนวันคริสมาสต์\n",
      "EN:   i m not sure if it s worth buying      buying the    \n",
      "-------------------------------------------------------------------\n",
      "Example :  19\n",
      "TH:  ฉันยังมั่นใจว่าแฟนๆของคริสเตียนร็อค รวมตัวฉันเองด้วย ได้ยินพวกเขาเพียงเพราะพวกเราต้องการแบบนั้น\n",
      "EN:   i m not sure if it s worth buying   buying  this  my  up with led\n",
      "-------------------------------------------------------------------\n",
      "Example :  20\n",
      "TH:  มันเล็กเกินไปสำหรับรองเท้าหรือข้อเท่าฉัน หลังจากลองมาหลายคู่แล้ว\n",
      "EN:   i m not sure if it s worth buying      buying the    \n",
      "-------------------------------------------------------------------\n",
      "Example :  21\n",
      "TH:  ความคิดที่ดี แนวคิดที่ดี แต่การดำเนินการไม่ดี\n",
      "EN:   i m not sure if it s worth buying      buying the    \n",
      "-------------------------------------------------------------------\n",
      "Example :  22\n",
      "TH:  ถ้าคุณต้องการรายชื่อบริษัทพร้อมข้อมูลแบบไม่มีค่าใช้จ่าย ค้นหาในเว็บไซต์\n",
      "EN:   i m not sure if it s worth buying      buying the    \n",
      "-------------------------------------------------------------------\n",
      "Example :  23\n",
      "TH:  หนังสือเล่มนี้สะท้อนความคิดที่ดีสองสามเร่อง แต่ก็เป็นสิ่งที่ฉันรู้อยู่อยู่แล้ว\n",
      "EN:   i m not sure if it s worth buying      buying the    \n",
      "-------------------------------------------------------------------\n",
      "Example :  24\n",
      "TH:  พวกเขามาถึงแล้วฉันก็ใส่เข้าไปบนหูฟังของฉัน พวกเขาไม่พอดีเลยด้วยซ้ำ\n",
      "EN:   i m not sure if it s worth buying      buying the  up with it\n",
      "-------------------------------------------------------------------\n",
      "Example :  25\n",
      "TH:  นี่เป็นสุญญากาศฮูเวอร์อันที่สองที่ฉันซื้อและฉันส่งมันคืนเพื่อคืนเงินแบบเต็มจำนวนเพราะมันแย่อ่ะ\n",
      "EN:   i d recomm buying another    with  buying  my  computer computer  up when plugged\n",
      "-------------------------------------------------------------------\n",
      "Example :  26\n",
      "TH:  เมื่อคุณได้รับน้ำร้อนแล้วให้เริ่มต้นถ้วยของคุณในขณะที่ยังรอรอบการต้มเพื่อที่ว่าเมื่อการต้มเบียร์ชนจะมีไอน้ำจำนวนมาก แต่ไม่มีหยดลงมา\n",
      "EN:   i m not sure if it s worth buying      buying the    \n",
      "-------------------------------------------------------------------\n",
      "Example :  27\n",
      "TH:  ฉันได้เรียนรู้บทเรียนของฉันแล้วถ้าคุณดูสื่อลามกไม่ว่าคนจะทำอะไรหลังปิดประตูคุณก็สกปรกไม่ว่าคุณจะแต่งงานหรือมีความสัมพันธ์แบบเปิด\n",
      "EN:   i m not sure if it s worth buying      buying the    \n",
      "-------------------------------------------------------------------\n",
      "Example :  28\n",
      "TH:  ไม่มีแสดงว่าผลิตภัณฑ์มีขนาดใหญ่แค่ไหนออนไลน์\n",
      "EN:   i m not sure if it s worth buying      buying the    \n",
      "-------------------------------------------------------------------\n",
      "Example :  29\n",
      "TH:  ชอบในของสิ่งนี้เช่นกัน\n",
      "EN:   i m not sure if it s worth buying      buying the    \n",
      "-------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "en_vocab = en_vectorization.get_vocabulary()\n",
    "en_index_lookup = dict(zip(range(len(en_vocab)), en_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = th_vectorization([input_sentence])\n",
    "\n",
    "    decoded_sentence = \"[start]\"\n",
    "\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = en_vectorization([decoded_sentence])[:, :-1]\n",
    "        predictions = my_transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
    "\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = en_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "test_th_texts = [pair[0] for pair in test_pairs]\n",
    "exp = 0\n",
    "for i in range(30):\n",
    "    input_sentence = random.choice(test_th_texts)\n",
    "    translated = decode_sequence(input_sentence)\n",
    "    print(\"Example : \",exp)\n",
    "    print(\"TH: \",test_th_texts[i])\n",
    "\n",
    "    translated = translated.replace(\"[start]\", \"\")\n",
    "    translated = translated.replace(\"[UNK]\", \"\")\n",
    "    translated = translated.replace(\"end\", \"\")\n",
    "    print(\"EN: \",translated)\n",
    "    exp = exp + 1\n",
    "    print(\"-------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ada86d8-2a8f-4407-b412-7c56aa0c7e43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
